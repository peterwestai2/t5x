from __gin__ import dynamic_registration

import __main__ as train_script
from t5.data import mixtures
from t5x import models
from t5x import partitioning
from t5x import utils
import t5x.atomic_eval_tasks_v1 as atomic_eval_tasks_v1 # to get my mixture

include "t5x/examples/t5/t5_1_1/xl.gin"

BATCH_SIZE = 512

MIXTURE_OR_TASK_NAME = "atomic_eval_mix_v1"

INITIAL_CHECKPOINT_PATH = %gin.REQUIRED
EVAL_OUTPUT_DIR = %gin.REQUIRED

DROPOUT_RATE = 0.0  # unused boilerplate


eval_script.evaluate:
  model = %MODEL  # imported from separate gin file
  dataset_cfg = @utils.DatasetConfig()
  partitioner = @partitioning.PjitPartitioner()
  restore_checkpoint_cfg = @utils.RestoreCheckpointConfig()
  output_dir = %EVAL_OUTPUT_DIR
  inference_evaluator_cls = @seqio.Evaluator


seqio.Evaluator:
  logger_cls = [@seqio.PyLoggingLogger, @seqio.TensorBoardLogger, @seqio.JSONLogger]
  num_examples = None  # Use all examples in the dataset.
  use_memory_cache = True


utils.DatasetConfig:
  mixture_or_task_name = %MIXTURE_OR_TASK_NAME
  task_feature_lengths = None  # Auto-computes the max feature lengths.
  split = 'validation'
  batch_size = 32
  shuffle = False
  seed = 42

partitioning.PjitPartitioner.num_partitions = 8
models.EncoderDecoderModel.predict_batch_with_aux.num_decodes = 4

utils.RestoreCheckpointConfig:
  path = %INITIAL_CHECKPOINT_PATH
  mode = 'specific'
