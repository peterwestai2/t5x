

from __gin__ import dynamic_registration

import __main__ as infer_script
from t5.data import mixtures
from t5x import models
from t5x import partitioning
from t5x import utils
import t5x.SoR_tasks as SoR_tasks
import seqio
from t5x import trainer
from t5x import decoding

include "t5x/examples/t5/t5_1_1/xxl.gin"
include "t5x/configs/runs/infer.gin"

BATCH_SIZE = 64


MIXTURE_OR_TASK_NAME = %gin.REQUIRED

MODE = 'predict'
SPLIT = 'validation'

MIXTURE_OR_TASK_NAME_EVAL = %MIXTURE_OR_TASK_NAME # eval dataset is usually the same as base, but we can specify a different one
TASK_FEATURE_LENGTHS = {"inputs": 128, "targets": 128}
DROPOUT_RATE = 0.0


partitioning.PjitPartitioner:
  num_partitions = 8
  
infer_script.infer:
  mode = %MODE
  checkpoint_ds_iter = False
  
  
  write_fn = @infer_script.write_inferences_to_file
  
infer_script.write_inferences_to_file:
  include_all_inputs = True
  task_ds = True
  #input_fields_to_include = ['inputs','targets']
  

  
utils.SaveCheckpointConfig:
  period = 10000


utils.DatasetConfig:
  mixture_or_task_name = %MIXTURE_OR_TASK_NAME_EVAL
  task_feature_lengths = %TASK_FEATURE_LENGTHS
  split = %SPLIT
  batch_size = %BATCH_SIZE
#  shuffle = True
#  seed = 42
#  use_cached = %USE_CACHED_TASKS
  pack = False
#  module = %MIXTURE_OR_TASK_MODULE

models.EncoderDecoderModel.predict_batch_with_aux.num_decodes = 2
models.EncoderDecoderModel.decode_fn = @decoding.temperature_sample
decoding.temperature_sample:
  max_decode_steps = 2036
  temperature = 1.0
  topk = 0
  topp = 0.7

seqio.Evaluator:
  logger_cls = [@seqio.PyLoggingLogger, @seqio.TensorBoardLogger, @seqio.JSONLogger]
  num_examples = 3000  # Use the first 3000 examples in the test set
#  use_memory_cache = True
